{
 "cells": [
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIkAAAAnCAYAAAA7MmtXAAADa0lEQVR4nO2c7ZHaMBCGn8ukACfpwOmASTrgOjBJBXE64ErIOB1wLTgdcCWE64B0kEAH5Ie0Y5299uFPBNYzwwCSPEj22vtqV+KOwK2Q2vcI+ABsgD+X607AN9YY43DZArHSNgP2wAnI7ffAjRNhLviyVJ5gjEBjhzGiwIxY1JQdatqfKNxTYGYsKQxmgTEGrc0J3RWpvO3fr4AHZMBf4BF4j3lK/Ktpew8cCaJ2Vmypuo4Yozv2SvsdZuYTmAlrzEXXOFE1BhG5yZidCvjFCWMoZWJbVxa0iS0vT5fd4yoETXK9yAV9UuoSjOZ4LpXf2/Kjcow2QwpcOTJL0diju5Q99Xok6JQbRPRF2UVk6EG0Jj2yQXdbQHA318wRWGGM4pstSzHGsCq1zSgisl+Bz/bzAvhkj3nX9GOikE/2dbDfY3vwzpZJ/Y6X8f6UIhdwoD4UPDa3Mo62xJi+p7QIkHVFTrAW0xf/pylm93gfuJVxeElKcQI1i5S7UBM4S7pnE4e2/kuNYzbIyS2fqNip0+bZOd0u9pIGwdSDqccxKzYUPtklowjElDOIEd3Tzjn1gZ0+TD2OrqSYm0QEp2iLHI/jFu6d5k6VxE/nts7NCazpFuZNGe/RPuU4uhJhnqTSV9dgEzzXRmXhl1C4BE34dRnMmvGDN1OMow8yJU2oJuJSPFoUdKeUuSuaPmIu5ooilLvHWP8v4Adm3v3Q4jdz+xvP1Kezm3D70sSY41hw/lNwC/xsqN/YPj00lNVFVi+KzAByqvGCNcVdWLeO8jUSprlTxh7HEByoLj3cK2XeIcJPWzsZOXV9HtFLxnc5U4yjD6JHXKRfYwj6QZHOa4tWoBB+fYXe2FPOqcbRlZSqgXovWl221McwmhbZtmGK4NUU4+hKRnVVmXfbHDThOjUR5wnRuXDACGxtnYgQNmLNGHGPTXrktY1Yc010zgZNo7i02YgVEp03SsbruaxzN2KFRGfgrI1YgyQ63wzQ2cC0yNPmN0bwNy02erTv5RnUd16uXvvifI7sKwjhK6XtRqxrSHQGBqTtRizB90RnYEDabsQS3PUzMcZYXA3i/ldJm8RlwDOaDGFNfdpBuIZEZ6AnXTZiufie6AwMQNuNWGV8T3QGBkKiqjJFbbu6r3Oi04cEX+B8Ygp38cREsYz/NpxkgD3LLpQAAAAASUVORK5CYII="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD随机梯度下降  \n",
    "\n",
    "每一个参数按照梯度的方向减小以追求最小化损失函数  \n",
    "    ![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python实现\n",
    "\n",
    "class SGD:\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self,params,grads):\n",
    "        for key in params.keys():\n",
    "            params[key] -= self.lr*grads[key]"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIkAAAA9CAYAAACZf0qqAAAE9klEQVR4nO2dPZbbNhCAPyc5gBJ36azcQHa6lNobcNcnCPcGSp0qT76BfITIpTttbhBtl1LOCRKpTKcUwDxiSYAiQYp/mu+9fbsCBBEgR5jBYDD7CmUKpPb3DHgNbIAv/XVHGRorjHC47IB54P1r4ACcga19rUyYGeZhL3PlCUYAQuwxgqTcCItA2bGkzZlMRSk3xJJMYBYYQQi970xYHRX4plm/lAGwBv4BPgLfYWaIf0vefwecUMP2ZthRVBtzjM1xCLTZY1Y/yg2wwjxwH2f8giCGbnKtTinD4owRlDxzW+czaBNbl18yu20LqE0yTuRhPnnqEoy98eypu7N1J0+dT6iUESMrFB8HwurkQNgeUTtlYohtkVcPa8JOtDJ7ZINfdQGqbsbKCbjHCMXPtizFCMK95/1rMq/se+BH+/cCeGfbfRu62Kvm/VV6ZE728J9Q34dyy1R2Dyv98FXP11+ijp3BE2uTLDEzwFvg0ZbNgL9tWVXduMUYXr51exMS27+T7c8Gv9+grXHEIIbmCfgdeLDld8Bvgf6OhhnZfsGRl06YPcXYhhAp1wl42eQ+d8bLbXM3iquNccQwIxPQ/LZ9QtjdPhrk5skAXVZUszFWXMd5k+K/weJgWpD1v41xxCLXTihuxKUMLCAoxk8iruBH4FOursoW9BZzc56Juxn3hNXTGvjFU37CPPQ58MGWxY5jQfUZcOdcz0Wufee59luKqibkXR08Pvdv1WinhPa/LTIj+GaAHeG4zybjaMqRolo7eMpGS343cUG9KXpJuyqnLBprR/jb33QcsfjUnLjOQ7u0vdDmEvgd9VYDT5hIqrYeyLO9fv7z8t/KSw+g7jhiWVJUK1LW9mqvEV83aPsXRp9/j9GjHyM+44hZ+vm2vGP4bPs0B94AP2FmkT/sdd5gDNv/nDZtjCOGB9s319D+1b5u6360whD2bsRXoJgvzT2XhUQPY90oYqNcUodlh7EkpPFsf4729dy22dsyqd/z0lZLyQ5uHSk/u6P0QMjH41L1MJYIim8FKQFLoRBHaa8MkDUlgT8OVQ5jpWSC4FsYyGziW10u0aOfk+HSYSwRkvwDnzt1PvW2JSdYfe8CK/WRGedPjMGf4p8tZJWWdww+8jJ67cH5e2Z/1AgeMXUOY7kzhutRFntja+vcdis0dGPUxBzGyhuwCZnd4zNg1WAdOU0OY4kBu+OlDeLmKamzcakMkDJBWBE+9wvZSmZL0e+xIhOissQ3ygiIPYwFRg2JIPj2sVzHmjJiYg5jCTILhWYbMWDVYJ0A4lWVZWqd6L4dYUfdpaxIg9jgU6qjh7EURVEURVEURVEURVF6ZirBs1MZx6CZSvDsVMYxSPoKnm17e7qvcaRM6AxvGa0Fz1ZkSbUI8bp0PQ6YsJDkA6G7Dp595DrHKscSBLzE9NGd1STpzmADgLoMnr1WpiPoJwi47kzSZ6alxnQRPHutTEcuXQcB1xWSPjMt1cIXT+IeGfwB8zDd7EIHzAA+YRLAvcefXSiEm+mo7J/3hCjLdORyzXFsMGkzXOSh5tXVlwufu7ZtXTWY0l12g2iuHTx7jUxHProMAo41XPvMtNSILoJn28505KPLIOBYIekr01JjugqebbLkrEKXQcBtCckoZhGhUfBsRbo4wd7FOCBeSBLMjJcyMgHpkkElkWvAZJ1pSntMRdgL/A9wV8Flpe6fiwAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Momentum  \n",
    "\n",
    "在梯度下降过程中加入了动量，即前面的梯度会影响本轮的梯度方向  \n",
    "\n",
    "更新方式：  \n",
    "    ![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python实现\n",
    "\n",
    "class Momentum:\n",
    "    def __init__(self, lr=0.01, momentum=0.9):\n",
    "        self.lr = lr\n",
    "        self.momentum = momentum\n",
    "        self.v = None\n",
    "    \n",
    "    def update(self, params, grads):\n",
    "        if self.v is None:\n",
    "            self.v = {}\n",
    "            for key,val in params.items():\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "            \n",
    "        for key in params.keys():\n",
    "            self.v[key] = self.momentum*self.v[key] - self.lr*grads[key]\n",
    "            params[key] += self.v[key]"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nestrov  \n",
    "Nestrov也是一种动量更新的方式，但为了加速收敛，提前按照之前的动量走了  \n",
    "一步，然后求导按照梯度在走一步  \n",
    "更新方式：  \n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaGrad  \n",
    "动量法旨在通过每个参数，在之前的迭代中的梯度，来改变当前位置参数的梯度  \n",
    "在梯度稳定的地方能够加速更新的速度，在梯度不稳定的地方能够文档梯度  \n",
    "\n",
    "而AdaGrad则是一种不同的思路，他是一种自适应优化算法，它通过每个参数的历史梯度，动太  \n",
    "更新每一个参数的学习率，使得每个参数的更新率都能够逐渐减少，前期梯度大的，学习率减少的  \n",
    "快，梯度小的，学习率减少的慢些  \n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python实现\n",
    "\n",
    "class AdaGrad:\n",
    "    def __init__(self,lr=0.01):\n",
    "        self.lr = lr\n",
    "        self.h = h\n",
    "    \n",
    "    def update(self, params,grads):\n",
    "        if self.h is None:\n",
    "            self.h = {}\n",
    "            for key,val in params.items():\n",
    "                self.h[key] = np.zeros_like(val)\n",
    "        \n",
    "        for key in params.keys():\n",
    "            self.h[key] += grads[key]*grads[key]\n",
    "            params[key] -= self.lr*grads[key]/(np.sqrt(self.h[key]) + 1e-7)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAO8AAABWCAYAAAAntcEEAAAJmklEQVR4nO2dP5fjthHAf47dpGMunbvIXZ4rxaVLbWd3OqdKGd430D2XqS66b6BrXcW6b7BXuvRu53S7bSrfbhd3cgHOI0QBJMG/oDC/9/R2RVESh8IAg8Fg5hMUZR7y4m8G/Bk4AI/zXc5opCKnkgg7TGO2uQVWjnP3wANwAo7F86WQipxKImSYBrqpHN9iGq2LO0yjXxKpyKkkxtpz7Mlz/onS/FwSqcipJMiGsoGvMY3Xdc4Jt6m5FEaR87P+16UoweyBX4F3wAvMaPPRc+4N8MwynTypyKkkwi2XpuEKM997cJx/h/HQLo1U5FQSYYdppC5OXDZecfpsx7yoEUhFTiUhTpiGXWVVvFZ18GyL49XlFvt9MTKJnDrnVaZCGuAHx2tbzFzvvnL8pjj+7HiPy5MbA6nIqSSEeFNdPOA2GR/wzwNjnR+mIqdSkLGs9b0cv4nnQ+Z1VRNwjztooW4eeMBtlsZAKnIqBUvrXTO6XbNEF2XFY+f5nD3G4WOHCu4xHtwn6ueHMRCdnBIZcsIfIRI7Mcqwwz+vyTA/ZDXELgY2dBsVVpiROydeh9MQRClnTA2/KzHJ4FpSWGF64Bx3fGws+JZDlkKGGSV3xWNL3CN6b4Zu+HP0SkPLkNNNwaRnriNm5ZUGv0REae32J6PlUmVqZMiG39X06kssyuvbHmYTs/Ku8e+QiZmc+iWYNQtwIPZZ582A74u/G8za1T9xr1X5eFW8ZwzWmOt6Bv4GvOby2oaQoQ9fEXcsa9M9vCfejsXHChNfXF1rtbkvzlsR9+8TzKl42JuFd45jTeSB54ew4XxEyCvPh5LB/vwujbjN6D/XyNt0DwXfmmashFh6US/T9Bl5/2P9L71T2/nrDvgCM/KOwRH4i/X8EbcC9JGhLzICxErbe/iIsVymslbG4IDZ9fNy7gsJoY/y2maH/HBtPHVHjEPgnm5ZA15S31By4OfKOWvcitJFBvmhbUThqybWI8bUnII17a2GW+Btzesh99DF3KPxJwHn2gEya+rN6SqzyjlHbPNLjPK+wsR0jvH51QXxG9yxpl1wWQs5RlFDvuMjl51AH+4Z7n6G3MMXXHamIcozN8+Y3zQjTHFhZjnn2pjwHnPTDgxvOm8qn5lhHENjmehdidnMXMo9HIp3c19AF/4w43d/wPTaQ84xXXOyI8Z0jdFr+DMRRd8UhNzDNcNZNFPxjnbLQDmRK/WnAeeugB8pG9vXwC/At8C/gT9hlHED/NDyM5+A7xjWpP0F+D/wV+AbzCgvXtIxZACzjPJEeAfxR8rsCjYZ8C+MwqyALzEOvo/A/wK/I5Sme2jzD+An4L8jX9OQ/IZxxH2O//eSnUGhZvSkxDA3GdJTKalEpu4xu8x5wch+ZJy5f1dC7uEdpuNqIsbE47KGfY+xgMBMDW4wqxBdFDdGORfDXFkG+8TD7olrw3Xbe7ihnflZl3hc0sXIuvtT8XxVvOeOciPJqXhue9RzykTlT3SL9pJoqqaoqyZilzNqNsSz2SCUWLYEtr2HbbcEtk08Lg3btXQoJqwrfYz9/jlJRc7RGDNia2xi2Yzf9h6GbMZvk3hcdk/5Rn0ZlVwdxoY4fvdU5FQSpCnxuCtkFcqkbfKodhpH4vLYTybnnEtFShrsMXM+idjybU4XB1nVAnnFedjid9b/kqkiBqdQKnIqiRCSeNweeez9tDLPOxav2e+LZT9xKnIqiRCaeBwuHTqyYR7cDp0YHDipyKkkRGjicSiTj4tD55bzuZ9dvzZkI8aYpCKnkgh1DXeHu1aPIB7XI5frmbLnWkatuR1VqcipJESXxOPCgbLhVtdNM+u1GEzJVORUEiI08biNjGa+UUscOjE4cFKRU0mMtonHXdziT0FTV1l+DmaTM4aNCcr1sqI0CT9wveuUqcipKIqiKIqiKIqiKJOgDitlyWjmCkWxiLmsqE1d5ooqe85DDjXcULkqllJWFNpnrrC5o1uSf0VZFLErL7TLXGFzIo5sJYOhm/GVpSLZHe3MFeBOz2MHUFwNc1VMUJS+7IFfMZkpXmBGVV8tpRtMdgt1ZilXT+xmc0jmCihzUSvK1ROz8oZmrhDnlu7OUZIgZuUNzVwhWSt8qWoXu9Fd57zKkhBFczmetpg5bbVMyU1x3FVSJ6ZKFYoyCLGOvF0yVzzgn+8ueh6sS0XKkpCCYK7MFfeYaoY2GWWCtyoH6nNMKcpiyDBKcMt5savYTMu2mSv2lClWJSRS5JPkb30KxM2ObkxQlohmrii4lvKD1yKHogRzLeUHr0UORWnNXOUHh15n0zKKSpJMXWZxgz/1ZR+upVykorRGsrhXt1XtOa+vYseVyubtLojXcGimlqMrOabzkmLVefGQGjWK0popyw+OWcl+CWUUM4zlIddqdyRbdO6tdGCK8oMhWeW7EnsZRVnq2HIZLJBzbgWcEnnYxHQtUeJa57VTiXyBUbKXlLGhD5jR4j3wBvg78DrgO4/Fd9zj339Zh30tdYwpR0jZxVvgbc3rh+KaXjccU5RWjF1+cMs088sllFF84jKO+MFxTFFaMUX5wQ3jm86xl1GU+a6NXNeiQ/eU+Ziq/ODYSzOxl1HMuew4hnRWVZfGYn8oAzFFmcUpgiJiLhcpqVZthswrfE1LTrKMtsPcH12PjwA1D89xzYG74NsKt0SaEqxrXLsyO2LmDtGhHbiOUTckwbrGtSuz4ZoDd6EuWkzW2B9qzhkKmZbIiNbnc3yfbaNx7cps7Bkm1nuP2/TeVI5PNTL3VV7BTrC+xu3kEuXVuHZlcdSNuiv6zedyus3H+yqvdGqS1ianjFGvspS4dkW5wDfqCnd0XxqbQ3lDE6wvIa5dUS4Qz2oTEhoaSl/llTxZMudu2lUWmmBdiD2uXUmQjPqotLoRZE2pKHVKUUcf5a3OQ3eOY673hSRYF2zzWJbM7E7CrtUbEqeuKJ2QRlYXEeZTyGoD9Tl7muirvLayiYL55uB1CrqjOW3rEuLalcS4w62kdaOuBCwIbeKnD5QNXx7y3dXjTSOXK/xRzFefo6hLgnWb2OPalQSRRl0dkXyNcMWls6hrWGjfkdemSXlFwVwJ1tt4zGOPa++NVkxYHpKnuBre55sLZ1zum95g6trGzDNm//We8wTrWXG8iUfMvfLdlzfFd1SrLCjKqEgkkYxKTaafPfqIR7pLCOaUI68g67o5OjdVroQnzKgiO23qEIfVln47ckKVVzy9tnNozeVGAA2QUJJCPKZTOly6jryKoliIQ2eMvNd136koygDoKJgwvwNN5XGg2eHQkQAAAABJRU5ErkJggg=="
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSprop  \n",
    "AdaGrad有个问题，那就是学习率会不断的衰减，这样就使得很多任务在达到最优解之前  \n",
    "学习率就已经过量减小，所以RMSprop采用指数衰减平均来慢慢丢掉先前的梯度历史  \n",
    "更新过程为：  \n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python实现\n",
    "\n",
    "class RMSprop:\n",
    "    def __init__(self, lr=0.01, decay_rate=0.99):\n",
    "        self.lr = lr\n",
    "        self.decay_rate = decay_rate\n",
    "        self.h = None\n",
    "    \n",
    "    def update(self,params,grads):\n",
    "        if self.h is None:\n",
    "            self.h = {}\n",
    "            for key,val in params.items():\n",
    "                self.h[key] = np.zeros_like(val)\n",
    "        \n",
    "        for key in params.keys():\n",
    "            self.h[key] *= self.decay_rate\n",
    "            self.h[key] += (1-self.decay_rate)*grads[key]*grads[key]\n",
    "            params[key] -= self.lr*grads[key]/(np.sqrt(self.h[key]) + 1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam  \n",
    "Adam方法结合动量和自适应，同时对学习率和梯度进行动态调整，如果说，动量相当于  \n",
    "给优化过程增加了惯性，自适应相当于给优化过程增加了阻力，速度越快，阻力也会越大  \n",
    "\n",
    "Adam首先计算了梯度的一阶矩估计和二阶矩估计，分别代表原来的动量和自适应部分  \n",
    "![title](https://pic2.zhimg.com/80/v2-06b3014d11c491c2aa1354a0ae19a41d_720w.jpg)\n",
    "\n",
    "β_1 与 β_2 是两个特有的超参数，一般设为0.9和0.999  \n",
    "\n",
    "对计算出的矩估计进行修正  \n",
    "![title](https://pic2.zhimg.com/80/v2-3cf005d6791897e1e5ad0f22a26b1725_720w.png)\n",
    "\n",
    "简单来说就是由于m和v的初始值为0，所以第一轮的时候会非常偏向于第二项，那么在后面计算更新值的时候  \n",
    "根据β_1 与 β_2的初始值来看就非常大，需要将其修正回来，根据β_1 与 β_2，所以如果不修正，对于\n",
    "最初的几次迭代会有很严重的影响；  \n",
    "最后就是更新参数值：  \n",
    "![title](https://pic4.zhimg.com/80/v2-f53a4adfd92b5ebbb949be8be68dc7d7_720w.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python实现\n",
    "\n",
    "class Adam:\n",
    "    def __init__(self, lr=0.001, beta1=0.9,beta2=0.999):\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        self.beta2  = beta2\n",
    "        self.iter = 0\n",
    "        self.m = None\n",
    "        self.v = None\n",
    "    \n",
    "    def update(self,params,grads):\n",
    "        if self.m is None:\n",
    "            self.m,self.v = {},{}\n",
    "            for key, val in parasm.items():\n",
    "                self.m[key] = np.zero_like(val)\n",
    "                self.v[key] = np.zeros_like(val)\n",
    "        \n",
    "        self.iter += 1\n",
    "        lr_t = self.lr * np.sqrt(1.0-self.beta2**self.iter)/(1.0 - self.beta1**self.iter)\n",
    "        for key in params.keys():\n",
    "            self.m[key] += (1-self.beta1)*(grads[key]-self.m[key])\n",
    "            self.v[key] += (1-self.beta2)*(grads[key]**2) - self.v[key]\n",
    "            \n",
    "            params[key] -=lr_t * self.m[key] / (np.sqrt(self.v[key])+1e-7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
